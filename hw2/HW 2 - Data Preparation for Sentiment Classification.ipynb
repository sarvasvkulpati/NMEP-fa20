{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2: Data Preparation for Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will prepare the IMDB movie review sentiment dataset. We will prepare it to fit a model that will predict whether a new review has a positive or negative sentiment. \n",
    "\n",
    "**Start by downloading the IMDB_Dataset from the .csv file into a pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Download the dataset into a Pandas DataFrame and display the first 5 rows\n",
    "## YOUR CODE HERE\n",
    "imdb = pd.read_csv('IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to process the data first, so that we have fixed length sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We want to split the dataset into reviews and labels. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_x = imdb['review']\n",
    "imdb_y = imdb['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the toBinary function created in HW 1 from this hw set (week 2)\n",
    "def toBinary(data, positive):\n",
    "    return data.apply(lambda x: 1 if x == positive else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the toBinary method to tranform the sentiment column into binary, 1 for positive and 0 for negative.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_y = toBinary(imdb_y, 'positive')\n",
    "imdb['sentiment'] = imdb_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors.\"\n",
    "    https://www.machinelearningplus.com/nlp/lemmatization-examples-python/\n",
    "\n",
    "<b>Lemmatize the sentences using any library from the article. Make sure to filter out non-alphabetical characters. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "\n",
    "def Lemmatize(data):\n",
    "    # Init the Wordnet Lemmatizer\n",
    "    data = data.str.split(\" |,|<br /><br />|\\\"|\\'|!\") # splits the data from sentences to words, feel free to change\n",
    "    lemmatizer =  WordNetLemmatizer()\n",
    "    \n",
    "    \n",
    "    for review in data:\n",
    "        for word in review:\n",
    "            word = lemmatizer.lemmatize(re.sub(r'\\W+', '', word))\n",
    "    \n",
    "    return data\n",
    "\n",
    "imdb_x = Lemmatize(imdb_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [One, of, the, other, reviewers, has, mentione...\n",
       "1        [A, wonderful, little, production., , The, fil...\n",
       "2        [I, thought, this, was, a, wonderful, way, to,...\n",
       "3        [Basically, there, s, a, family, where, a, lit...\n",
       "4        [Petter, Mattei, s, , Love, in, the, Time, of,...\n",
       "                               ...                        \n",
       "49995    [I, thought, this, movie, did, a, down, right,...\n",
       "49996    [Bad, plot, , bad, dialogue, , bad, acting, , ...\n",
       "49997    [I, am, a, Catholic, taught, in, parochial, el...\n",
       "49998    [I, m, going, to, have, to, disagree, with, th...\n",
       "49999    [No, one, expects, the, Star, Trek, movies, to...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has to be put into integer form, so each integer represents a unique word, 0 represents a PAD character, 1 represents a START character and 2 represents a character that is unknown because it is not in the top `num_words`. \n",
    "Thus 3 represents the first real word. \n",
    "\n",
    "Also the words should be in decreasing order of frequency, so the word that 3 represents is the most common word in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete CreateDict which will take in a data column <br>\n",
    "    1) Create a Dict that maps {Word: Apperances in dataset} \n",
    "       <i> Do not implement dictionary keys for PAD, START, and unknown characters (except \"\" see hint), this will be done later. </i>\n",
    "<br>\n",
    "    2) Choose the top N most recurring words and give ascending indexes starting at 3 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 3\n",
      "a 4\n",
      "and 5\n",
      "of 6\n",
      "to 7\n",
      "is 8\n",
      "in 9\n",
      "I 10\n",
      "it 11\n",
      "that 12\n",
      "s 13\n",
      "this 14\n",
      "was 15\n",
      "The 16\n",
      "as 17\n",
      "with 18\n",
      "for 19\n",
      "movie 20\n",
      "but 21\n",
      "film 22\n",
      "t 23\n",
      "on 24\n",
      "you 25\n",
      "are 26\n",
      "his 27\n",
      "have 28\n",
      "not 29\n",
      "be 30\n",
      "he 31\n",
      "one 32\n",
      "at 33\n",
      "by 34\n",
      "an 35\n",
      "who 36\n",
      "all 37\n",
      "they 38\n",
      "from 39\n",
      "like 40\n",
      "It 41\n",
      "so 42\n",
      "has 43\n",
      "about 44\n",
      "just 45\n",
      "or 46\n",
      "her 47\n",
      "out 48\n",
      "This 49\n",
      "some 50\n",
      "can 51\n",
      "very 52\n",
      "more 53\n",
      "good 54\n",
      "what 55\n",
      "would 56\n",
      "there 57\n",
      "when 58\n",
      "up 59\n",
      "if 60\n",
      "their 61\n",
      "really 62\n",
      "only 63\n",
      "had 64\n",
      "she 65\n",
      "which 66\n",
      "even 67\n",
      "see 68\n",
      "were 69\n",
      "my 70\n",
      "no 71\n",
      "than 72\n",
      "story 73\n",
      "- 74\n",
      "time 75\n",
      "been 76\n",
      "me 77\n",
      "into 78\n",
      "get 79\n",
      "much 80\n",
      "will 81\n",
      "we 82\n",
      "because 83\n",
      "other 84\n",
      "people 85\n",
      "most 86\n",
      "great 87\n",
      "do 88\n",
      "could 89\n",
      "make 90\n",
      "first 91\n",
      "how 92\n",
      "bad 93\n",
      "also 94\n",
      "its 95\n",
      "don 96\n",
      "any 97\n",
      "him 98\n",
      "made 99\n",
      "But 100\n",
      "think 101\n",
      "And 102\n",
      "well 103\n",
      "it. 104\n",
      "way 105\n",
      "then 106\n",
      "too 107\n",
      "being 108\n",
      "them 109\n",
      "many 110\n",
      "characters 111\n",
      "character 112\n",
      "movie. 113\n",
      "movies 114\n",
      "never 115\n",
      "There 116\n",
      "two 117\n",
      "A 118\n",
      "In 119\n",
      "know 120\n",
      "where 121\n",
      "little 122\n",
      "after 123\n",
      "films 124\n",
      "watch 125\n",
      "seen 126\n",
      "acting 127\n",
      "plot 128\n",
      "your 129\n",
      "did 130\n",
      "love 131\n",
      "If 132\n",
      ". 133\n",
      "does 134\n",
      "best 135\n",
      "ever 136\n",
      "show 137\n",
      "He 138\n",
      "film. 139\n",
      "i 140\n",
      "ve 141\n",
      "say 142\n",
      "off 143\n",
      "over 144\n",
      "still 145\n",
      "better 146\n",
      "scene 147\n",
      "should 148\n",
      "m 149\n",
      "such 150\n",
      "these 151\n",
      "life 152\n",
      "scenes 153\n",
      "something 154\n",
      "through 155\n",
      "doesn 156\n",
      "go 157\n",
      "those 158\n",
      "didn 159\n",
      "end 160\n",
      "man 161\n",
      "real 162\n",
      "back 163\n",
      "makes 164\n",
      "find 165\n",
      "watching 166\n",
      "actually 167\n",
      "thing 168\n",
      "actors 169\n",
      "going 170\n",
      "few 171\n",
      "same 172\n",
      "lot 173\n",
      "re 174\n",
      "look 175\n",
      "while 176\n",
      "years 177\n",
      "old 178\n",
      "& 179\n",
      "here 180\n",
      "want 181\n",
      "why 182\n",
      "quite 183\n",
      "before 184\n",
      "every 185\n",
      "nothing 186\n",
      "seems 187\n",
      "pretty 188\n",
      "another 189\n",
      "part 190\n",
      "got 191\n",
      "work 192\n",
      "fact 193\n",
      "funny 194\n",
      "director 195\n",
      "though 196\n",
      "You 197\n",
      "As 198\n",
      "thought 199\n",
      "around 200\n",
      "cast 201\n",
      "What 202\n",
      "take 203\n",
      "They 204\n",
      "give 205\n",
      "between 206\n",
      "things 207\n",
      "young 208\n",
      "isn 209\n",
      "may 210\n",
      "enough 211\n",
      "down 212\n",
      "gets 213\n",
      "own 214\n",
      "saw 215\n",
      "must 216\n",
      "always 217\n",
      "whole 218\n",
      "horror 219\n",
      "without 220\n",
      "us 221\n",
      "almost 222\n",
      "least 223\n",
      "ll 224\n",
      "both 225\n",
      "might 226\n",
      "big 227\n",
      "bit 228\n",
      "come 229\n",
      "new 230\n",
      "long 231\n",
      "now 232\n",
      "original 233\n",
      "am 234\n",
      "feel 235\n",
      "action 236\n",
      "far 237\n",
      "music 238\n",
      "interesting 239\n",
      "guy 240\n",
      "She 241\n",
      "So 242\n",
      "probably 243\n",
      "kind 244\n",
      "done 245\n",
      "That 246\n",
      "anything 247\n",
      "again 248\n",
      "point 249\n",
      "role 250\n",
      "found 251\n",
      "world 252\n",
      "series 253\n",
      "right 254\n",
      "rather 255\n",
      "last 256\n",
      "comedy 257\n",
      "times 258\n",
      "script 259\n",
      "minutes 260\n",
      "since 261\n",
      "When 262\n",
      "each 263\n",
      "trying 264\n",
      "family 265\n",
      "making 266\n",
      "comes 267\n",
      "performance 268\n",
      "worst 269\n",
      "believe 270\n",
      "TV 271\n",
      "d 272\n",
      "put 273\n",
      "our 274\n",
      "woman 275\n",
      "played 276\n",
      "main 277\n",
      "goes 278\n",
      "time. 279\n",
      "anyone 280\n",
      ") 281\n",
      "One 282\n",
      "course 283\n",
      "away 284\n",
      "wasn 285\n",
      "girl 286\n",
      "fun 287\n",
      "looks 288\n",
      "worth 289\n",
      "looking 290\n",
      "hard 291\n",
      "watched 292\n",
      "shows 293\n",
      "different 294\n",
      "plays 295\n",
      "having 296\n",
      "yet 297\n",
      "seem 298\n",
      "For 299\n",
      "takes 300\n",
      "sure 301\n",
      "someone 302\n",
      "especially 303\n",
      "American 304\n",
      "My 305\n",
      "We 306\n",
      "set 307\n",
      "said 308\n",
      "All 309\n",
      "DVD 310\n",
      "reason 311\n",
      "Not 312\n",
      "play 313\n",
      "during 314\n",
      "three 315\n",
      "left 316\n",
      "John 317\n",
      "effects 318\n",
      "However 319\n",
      "actor 320\n",
      "sense 321\n",
      "ending 322\n",
      "place 323\n",
      "true 324\n",
      "special 325\n",
      "job 326\n",
      "book 327\n",
      "seeing 328\n",
      "used 329\n",
      "simply 330\n",
      "completely 331\n",
      "everything 332\n",
      "idea 333\n",
      "beautiful 334\n",
      "version 335\n",
      "money 336\n",
      "everyone 337\n",
      "fan 338\n",
      "let 339\n",
      "audience 340\n",
      "shot 341\n",
      "read 342\n",
      "wife 343\n",
      "use 344\n",
      "nice 345\n",
      "-- 346\n",
      "himself 347\n",
      "need 348\n",
      "once 349\n",
      "excellent 350\n",
      "screen 351\n",
      "2 352\n",
      "help 353\n",
      "together 354\n",
      "day 355\n",
      "later 356\n",
      "recommend 357\n",
      "until 358\n",
      "truly 359\n",
      "couple 360\n",
      "short 361\n",
      "poor 362\n",
      "rest 363\n",
      "try 364\n",
      "given 365\n",
      "high 366\n",
      "less 367\n",
      "came 368\n",
      "10 369\n",
      "Hollywood 370\n",
      "won 371\n",
      "getting 372\n",
      "half 373\n",
      "tell 374\n",
      "enjoy 375\n",
      "else 376\n",
      "understand 377\n",
      "After 378\n",
      "keep 379\n",
      "At 380\n",
      "second 381\n",
      "along 382\n",
      "To 383\n",
      "gives 384\n",
      "year 385\n",
      "father 386\n",
      "start 387\n",
      "Even 388\n",
      "kids 389\n",
      "them. 390\n",
      "mean 391\n",
      "playing 392\n",
      "couldn 393\n",
      "Well 394\n",
      "(and 395\n",
      "went 396\n",
      "THE 397\n",
      "friends 398\n",
      "small 399\n",
      "No 400\n",
      "full 401\n",
      "production 402\n",
      "men 403\n",
      "women 404\n",
      "performances 405\n",
      "become 406\n",
      "doing 407\n",
      "remember 408\n",
      "however 409\n",
      "early 410\n",
      "camera 411\n",
      "liked 412\n",
      "entire 413\n",
      "mind 414\n",
      "home 415\n",
      "supposed 416\n",
      "classic 417\n",
      "often 418\n",
      "felt 419\n",
      "maybe 420\n",
      "human 421\n",
      "next 422\n",
      "person 423\n",
      "absolutely 424\n",
      "line 425\n",
      "piece 426\n",
      "stupid 427\n",
      "wonderful 428\n",
      "sort 429\n",
      "black 430\n",
      "definitely 431\n",
      "moments 432\n",
      "certainly 433\n",
      "His 434\n",
      "sex 435\n",
      "budget 436\n",
      "instead 437\n",
      "one. 438\n",
      "seemed 439\n",
      "against 440\n",
      "boring 441\n",
      "While 442\n",
      "Don 443\n",
      "Then 444\n",
      "several 445\n",
      "him. 446\n",
      "name 447\n",
      "waste 448\n",
      "becomes 449\n",
      "school 450\n",
      "loved 451\n",
      "this. 452\n",
      "death 453\n",
      "totally 454\n",
      "wanted 455\n",
      "video 456\n",
      "Also 457\n",
      "lines 458\n",
      "perfect 459\n",
      "dialogue 460\n",
      "although 461\n",
      "night 462\n",
      "able 463\n",
      "episode 464\n",
      "top 465\n",
      "well. 466\n",
      "Of 467\n",
      "friend 468\n",
      "itself 469\n",
      "hope 470\n",
      "called 471\n",
      "written 472\n",
      "me. 473\n",
      "Some 474\n",
      "Now 475\n",
      "Â– 476\n",
      "live 477\n",
      "mother 478\n",
      "face 479\n",
      "terrible 480\n",
      "case 481\n",
      "already 482\n",
      "lead 483\n",
      "story. 484\n",
      "wrong 485\n",
      "either 486\n",
      "wants 487\n",
      "turn 488\n",
      "based 489\n",
      "guys 490\n",
      "sound 491\n",
      "tries 492\n",
      "style 493\n",
      "low 494\n",
      "title 495\n",
      "all. 496\n",
      "gave 497\n",
      "children 498\n",
      "beginning 499\n",
      "war 500\n",
      "problem 501\n",
      "laugh 502\n",
      "final 503\n",
      "care 504\n",
      "house 505\n",
      "head 506\n",
      "others 507\n",
      "enjoyed 508\n",
      "How 509\n",
      "finally 510\n",
      "stars 511\n",
      "awful 512\n",
      "turns 513\n",
      "guess 514\n",
      "under 515\n",
      "good. 516\n",
      "Michael 517\n",
      "entertaining 518\n",
      "boy 519\n",
      "With 520\n",
      "lost 521\n",
      "Why 522\n",
      "life. 523\n",
      "starts 524\n",
      "(the 525\n",
      "New 526\n",
      "took 527\n",
      "example 528\n",
      "fine 529\n",
      "star 530\n",
      "favorite 531\n",
      "humor 532\n",
      "fans 533\n",
      "writing 534\n",
      "quality 535\n",
      "worse 536\n",
      "3 537\n",
      "Just 538\n",
      "direction 539\n",
      "behind 540\n",
      "( 541\n",
      "works 542\n",
      "lives 543\n",
      "says 544\n",
      "group 545\n",
      "Mr. 546\n",
      "viewer 547\n",
      "kill 548\n",
      "decent 549\n",
      "game 550\n",
      "picture 551\n",
      "expect 552\n",
      "drama 553\n",
      "heard 554\n",
      "perhaps 555\n",
      "cannot 556\n",
      "movies. 557\n",
      "throughout 558\n",
      "son 559\n",
      "extremely 560\n",
      "lack 561\n",
      "looked 562\n",
      "dead 563\n",
      "car 564\n",
      "side 565\n",
      "myself 566\n",
      "past 567\n",
      "parts 568\n",
      "run 569\n",
      "wouldn 570\n",
      "late 571\n",
      "that. 572\n",
      "On 573\n",
      "feeling 574\n",
      "directed 575\n",
      "dark 576\n",
      "amazing 577\n",
      "attempt 578\n",
      "killed 579\n",
      "thinking 580\n",
      "matter 581\n",
      "killer 582\n",
      "cinema 583\n",
      "told 584\n",
      "act 585\n",
      "horrible 586\n",
      "type 587\n",
      "evil 588\n",
      "taken 589\n",
      "fight 590\n",
      "leave 591\n",
      "brilliant 592\n",
      "out. 593\n",
      "obviously 594\n",
      "complete 595\n",
      "town 596\n",
      "shown 597\n",
      "David 598\n",
      "happens 599\n",
      "Although 600\n",
      "wonder 601\n",
      "here. 602\n",
      "girls 603\n",
      "particularly 604\n",
      "strong 605\n",
      "Oh 606\n",
      "kid 607\n",
      "opening 608\n",
      "bad. 609\n",
      "across 610\n",
      "white 611\n",
      "highly 612\n",
      "coming 613\n",
      "exactly 614\n",
      "James 615\n",
      "known 616\n",
      "actress 617\n",
      "serious 618\n",
      "hour 619\n",
      "themselves 620\n",
      "obvious 621\n",
      "daughter 622\n",
      "save 623\n",
      "Robert 624\n",
      "involved 625\n",
      "whose 626\n",
      "close 627\n",
      "end. 628\n",
      "history 629\n",
      "eyes 630\n",
      "again. 631\n",
      "stuff 632\n",
      "child 633\n",
      "hand 634\n",
      "sometimes 635\n",
      "moment 636\n",
      "stop 637\n",
      "soon 638\n",
      "turned 639\n",
      "finds 640\n",
      "stories 641\n",
      "is. 642\n",
      "seen. 643\n",
      "First 644\n",
      "way. 645\n",
      "number 646\n",
      "huge 647\n",
      "somewhat 648\n",
      "chance 649\n",
      "score 650\n",
      "saying 651\n",
      "days 652\n",
      "knew 653\n",
      "flick 654\n",
      "wish 655\n",
      "started 656\n",
      "voice 657\n",
      "slow 658\n",
      "female 659\n",
      "taking 660\n",
      "hit 661\n",
      "despite 662\n",
      "running 663\n",
      "art 664\n",
      "relationship 665\n",
      "local 666\n",
      "simple 667\n",
      "except 668\n",
      "usually 669\n",
      "films. 670\n",
      "order 671\n",
      "heart 672\n",
      "English 673\n",
      "husband 674\n",
      "tells 675\n",
      "living 676\n",
      "aren 677\n",
      "today 678\n",
      "important 679\n",
      "released 680\n",
      "including 681\n",
      "shots 682\n",
      "call 683\n",
      "police 684\n",
      "single 685\n",
      "jokes 686\n",
      "genre 687\n",
      "violence 688\n",
      "her. 689\n",
      "(I 690\n",
      "usual 691\n",
      "major 692\n",
      "due 693\n",
      "talking 694\n",
      "British 695\n",
      "From 696\n",
      "ends 697\n",
      "cinematography 698\n",
      "knows 699\n",
      "cool 700\n",
      "happened 701\n",
      "on. 702\n",
      "cut 703\n",
      "1 704\n",
      "change 705\n",
      "interest 706\n",
      "song 707\n",
      "Jack 708\n",
      "mostly 709\n",
      "sad 710\n",
      "hero 711\n",
      "brother 712\n",
      "Unfortunately 713\n",
      "experience 714\n",
      "appears 715\n",
      "Man 716\n",
      "happen 717\n",
      "giving 718\n",
      "musical 719\n",
      "Maybe 720\n",
      "hours 721\n",
      "cheap 722\n",
      "haven 723\n",
      "bring 724\n",
      "beyond 725\n",
      "reality 726\n",
      "clearly 727\n",
      "mention 728\n",
      "murder 729\n",
      "yourself 730\n",
      "modern 731\n",
      "too. 732\n",
      "upon 733\n",
      "falls 734\n",
      "documentary 735\n",
      "talent 736\n",
      "sets 737\n",
      "silly 738\n",
      "similar 739\n",
      "funny. 740\n",
      "certain 741\n",
      "novel 742\n",
      "annoying 743\n",
      "sequence 744\n",
      "view 745\n",
      "characters. 746\n",
      "tried 747\n",
      "needs 748\n",
      "strange 749\n",
      "events 750\n",
      "gore 751\n",
      "roles 752\n",
      "supporting 753\n",
      "showing 754\n",
      "body 755\n",
      "romantic 756\n",
      "? 757\n",
      "George 758\n",
      "hilarious 759\n",
      "kept 760\n",
      "easily 761\n",
      "Yes 762\n",
      "named 763\n",
      "feels 764\n",
      "OK 765\n",
      "comic 766\n",
      "word 767\n",
      "problems 768\n",
      "words 769\n",
      "bunch 770\n",
      "5 771\n",
      "episodes 772\n",
      "actual 773\n",
      "An 774\n",
      "career 775\n",
      "attention 776\n",
      "typical 777\n",
      "near 778\n",
      "brought 779\n",
      "alone 780\n",
      "blood 781\n",
      "... 782\n",
      "fall 783\n",
      "opinion 784\n",
      "happy 785\n",
      "hate 786\n",
      "songs 787\n",
      "within 788\n",
      "nearly 789\n",
      "above 790\n",
      "ridiculous 791\n",
      "using 792\n",
      "light 793\n",
      "surprised 794\n",
      "doubt 795\n",
      "Like 796\n",
      "dialog 797\n",
      "working 798\n",
      "country 799\n",
      "whether 800\n",
      "among 801\n",
      "clear 802\n",
      "ones 803\n",
      "ago 804\n",
      "age 805\n",
      "greatest 806\n",
      "room 807\n",
      "Peter 808\n",
      "Its 809\n",
      "four 810\n",
      "Is 811\n",
      "talk 812\n",
      "Most 813\n",
      "writer 814\n",
      "4 815\n",
      "basically 816\n",
      "means 817\n",
      "French 818\n",
      "middle 819\n",
      "level 820\n",
      "moving 821\n",
      "better. 822\n",
      "possible 823\n",
      "decided 824\n",
      "none 825\n",
      "there. 826\n",
      "review 827\n",
      "power 828\n",
      "theme 829\n",
      "overall 830\n",
      "buy 831\n",
      "comments 832\n",
      "hear 833\n",
      "These 834\n",
      "television 835\n",
      "(which 836\n",
      "team 837\n",
      "Richard 838\n",
      "easy 839\n",
      "famous 840\n",
      "message 841\n",
      "). 842\n",
      "elements 843\n",
      "deal 844\n",
      "crap 845\n",
      "sit 846\n",
      "add 847\n",
      "subject 848\n",
      "Who 849\n",
      "Her 850\n",
      "watch. 851\n",
      "work. 852\n",
      "soundtrack 853\n",
      "filmed 854\n",
      "God 855\n",
      "learn 856\n",
      "scary 857\n",
      "lots 858\n",
      "you. 859\n",
      "show. 860\n",
      "enjoyable 861\n",
      "(as 862\n",
      "hell 863\n",
      "stay 864\n",
      "ten 865\n",
      "leads 866\n",
      "Tom 867\n",
      "parents 868\n",
      "became 869\n",
      "five 870\n",
      "Overall 871\n",
      "begins 872\n",
      "etc. 873\n",
      "predictable 874\n",
      "emotional 875\n",
      "up. 876\n",
      "difficult 877\n",
      "straight 878\n",
      "move 879\n",
      "Paul 880\n",
      "particular 881\n",
      "leaves 882\n",
      "By 883\n",
      "figure 884\n",
      "apparently 885\n",
      "killing 886\n",
      "reviews 887\n",
      "effort 888\n",
      "Here 889\n",
      "dull 890\n",
      "(or 891\n",
      "feature 892\n",
      "keeps 893\n",
      "storyline 894\n",
      "sexual 895\n",
      "previous 896\n",
      "meets 897\n",
      "form 898\n",
      "premise 899\n",
      "forced 900\n",
      "editing 901\n",
      "release 902\n",
      "write 903\n",
      "NOT 904\n",
      "herself 905\n",
      "sequel 906\n",
      "poorly 907\n",
      "realize 908\n",
      "points 909\n",
      "needed 910\n",
      "viewers 911\n",
      "stand 912\n",
      "ways 913\n",
      "personal 914\n",
      "suspense 915\n",
      "sister 916\n",
      "somehow 917\n",
      "weak 918\n",
      "Dr. 919\n",
      "realistic 920\n",
      "future 921\n",
      "King 922\n",
      "York 923\n",
      "tale 924\n",
      "rent 925\n",
      "possibly 926\n",
      "seriously 927\n",
      "sequences 928\n",
      "whom 929\n",
      "various 930\n",
      "thriller 931\n",
      "20 932\n",
      "brings 933\n",
      "expected 934\n",
      "incredibly 935\n",
      "interested 936\n",
      "reading 937\n",
      "towards 938\n",
      "Lee 939\n",
      "class 940\n",
      "animation 941\n",
      "gone 942\n",
      "average 943\n",
      "footage 944\n",
      "features 945\n",
      "monster 946\n",
      "viewing 947\n",
      "Japanese 948\n",
      "fantastic 949\n",
      "city 950\n",
      "admit 951\n",
      "begin 952\n",
      "Another 953\n",
      "male 954\n",
      "older 955\n",
      "atmosphere 956\n",
      "fairly 957\n",
      "appear 958\n",
      "follow 959\n",
      "meet 960\n",
      "Oscar 961\n",
      "entertainment 962\n",
      "crew 963\n",
      "open 964\n",
      "material 965\n",
      "result 966\n",
      "eventually 967\n",
      "minute 968\n",
      "nor 969\n",
      "manages 970\n",
      "Disney 971\n",
      "spent 972\n",
      "imagine 973\n",
      "Joe 974\n",
      "worked 975\n",
      "leading 976\n",
      "Or 977\n",
      "80 978\n",
      "total 979\n",
      "theater 980\n",
      "cheesy 981\n",
      "crime 982\n",
      "forget 983\n",
      "disappointed 984\n",
      "unique 985\n",
      "meant 986\n",
      "War 987\n",
      "attempts 988\n",
      "surprise 989\n",
      "wait 990\n",
      "dramatic 991\n",
      "America 992\n",
      "political 993\n",
      "period 994\n",
      "comment 995\n",
      "memorable 996\n",
      "deep 997\n",
      "create 998\n",
      "writers 999\n",
      "front 1000\n",
      "Great 1001\n",
      "plot. 1002\n",
      "Instead 1003\n",
      "fast 1004\n",
      "third 1005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 3,\n",
       " 'a': 4,\n",
       " 'and': 5,\n",
       " 'of': 6,\n",
       " 'to': 7,\n",
       " 'is': 8,\n",
       " 'in': 9,\n",
       " 'I': 10,\n",
       " 'it': 11,\n",
       " 'that': 12,\n",
       " 's': 13,\n",
       " 'this': 14,\n",
       " 'was': 15,\n",
       " 'The': 16,\n",
       " 'as': 17,\n",
       " 'with': 18,\n",
       " 'for': 19,\n",
       " 'movie': 20,\n",
       " 'but': 21,\n",
       " 'film': 22,\n",
       " 't': 23,\n",
       " 'on': 24,\n",
       " 'you': 25,\n",
       " 'are': 26,\n",
       " 'his': 27,\n",
       " 'have': 28,\n",
       " 'not': 29,\n",
       " 'be': 30,\n",
       " 'he': 31,\n",
       " 'one': 32,\n",
       " 'at': 33,\n",
       " 'by': 34,\n",
       " 'an': 35,\n",
       " 'who': 36,\n",
       " 'all': 37,\n",
       " 'they': 38,\n",
       " 'from': 39,\n",
       " 'like': 40,\n",
       " 'It': 41,\n",
       " 'so': 42,\n",
       " 'has': 43,\n",
       " 'about': 44,\n",
       " 'just': 45,\n",
       " 'or': 46,\n",
       " 'her': 47,\n",
       " 'out': 48,\n",
       " 'This': 49,\n",
       " 'some': 50,\n",
       " 'can': 51,\n",
       " 'very': 52,\n",
       " 'more': 53,\n",
       " 'good': 54,\n",
       " 'what': 55,\n",
       " 'would': 56,\n",
       " 'there': 57,\n",
       " 'when': 58,\n",
       " 'up': 59,\n",
       " 'if': 60,\n",
       " 'their': 61,\n",
       " 'really': 62,\n",
       " 'only': 63,\n",
       " 'had': 64,\n",
       " 'she': 65,\n",
       " 'which': 66,\n",
       " 'even': 67,\n",
       " 'see': 68,\n",
       " 'were': 69,\n",
       " 'my': 70,\n",
       " 'no': 71,\n",
       " 'than': 72,\n",
       " 'story': 73,\n",
       " '-': 74,\n",
       " 'time': 75,\n",
       " 'been': 76,\n",
       " 'me': 77,\n",
       " 'into': 78,\n",
       " 'get': 79,\n",
       " 'much': 80,\n",
       " 'will': 81,\n",
       " 'we': 82,\n",
       " 'because': 83,\n",
       " 'other': 84,\n",
       " 'people': 85,\n",
       " 'most': 86,\n",
       " 'great': 87,\n",
       " 'do': 88,\n",
       " 'could': 89,\n",
       " 'make': 90,\n",
       " 'first': 91,\n",
       " 'how': 92,\n",
       " 'bad': 93,\n",
       " 'also': 94,\n",
       " 'its': 95,\n",
       " 'don': 96,\n",
       " 'any': 97,\n",
       " 'him': 98,\n",
       " 'made': 99,\n",
       " 'But': 100,\n",
       " 'think': 101,\n",
       " 'And': 102,\n",
       " 'well': 103,\n",
       " 'it.': 104,\n",
       " 'way': 105,\n",
       " 'then': 106,\n",
       " 'too': 107,\n",
       " 'being': 108,\n",
       " 'them': 109,\n",
       " 'many': 110,\n",
       " 'characters': 111,\n",
       " 'character': 112,\n",
       " 'movie.': 113,\n",
       " 'movies': 114,\n",
       " 'never': 115,\n",
       " 'There': 116,\n",
       " 'two': 117,\n",
       " 'A': 118,\n",
       " 'In': 119,\n",
       " 'know': 120,\n",
       " 'where': 121,\n",
       " 'little': 122,\n",
       " 'after': 123,\n",
       " 'films': 124,\n",
       " 'watch': 125,\n",
       " 'seen': 126,\n",
       " 'acting': 127,\n",
       " 'plot': 128,\n",
       " 'your': 129,\n",
       " 'did': 130,\n",
       " 'love': 131,\n",
       " 'If': 132,\n",
       " '.': 133,\n",
       " 'does': 134,\n",
       " 'best': 135,\n",
       " 'ever': 136,\n",
       " 'show': 137,\n",
       " 'He': 138,\n",
       " 'film.': 139,\n",
       " 'i': 140,\n",
       " 've': 141,\n",
       " 'say': 142,\n",
       " 'off': 143,\n",
       " 'over': 144,\n",
       " 'still': 145,\n",
       " 'better': 146,\n",
       " 'scene': 147,\n",
       " 'should': 148,\n",
       " 'm': 149,\n",
       " 'such': 150,\n",
       " 'these': 151,\n",
       " 'life': 152,\n",
       " 'scenes': 153,\n",
       " 'something': 154,\n",
       " 'through': 155,\n",
       " 'doesn': 156,\n",
       " 'go': 157,\n",
       " 'those': 158,\n",
       " 'didn': 159,\n",
       " 'end': 160,\n",
       " 'man': 161,\n",
       " 'real': 162,\n",
       " 'back': 163,\n",
       " 'makes': 164,\n",
       " 'find': 165,\n",
       " 'watching': 166,\n",
       " 'actually': 167,\n",
       " 'thing': 168,\n",
       " 'actors': 169,\n",
       " 'going': 170,\n",
       " 'few': 171,\n",
       " 'same': 172,\n",
       " 'lot': 173,\n",
       " 're': 174,\n",
       " 'look': 175,\n",
       " 'while': 176,\n",
       " 'years': 177,\n",
       " 'old': 178,\n",
       " '&': 179,\n",
       " 'here': 180,\n",
       " 'want': 181,\n",
       " 'why': 182,\n",
       " 'quite': 183,\n",
       " 'before': 184,\n",
       " 'every': 185,\n",
       " 'nothing': 186,\n",
       " 'seems': 187,\n",
       " 'pretty': 188,\n",
       " 'another': 189,\n",
       " 'part': 190,\n",
       " 'got': 191,\n",
       " 'work': 192,\n",
       " 'fact': 193,\n",
       " 'funny': 194,\n",
       " 'director': 195,\n",
       " 'though': 196,\n",
       " 'You': 197,\n",
       " 'As': 198,\n",
       " 'thought': 199,\n",
       " 'around': 200,\n",
       " 'cast': 201,\n",
       " 'What': 202,\n",
       " 'take': 203,\n",
       " 'They': 204,\n",
       " 'give': 205,\n",
       " 'between': 206,\n",
       " 'things': 207,\n",
       " 'young': 208,\n",
       " 'isn': 209,\n",
       " 'may': 210,\n",
       " 'enough': 211,\n",
       " 'down': 212,\n",
       " 'gets': 213,\n",
       " 'own': 214,\n",
       " 'saw': 215,\n",
       " 'must': 216,\n",
       " 'always': 217,\n",
       " 'whole': 218,\n",
       " 'horror': 219,\n",
       " 'without': 220,\n",
       " 'us': 221,\n",
       " 'almost': 222,\n",
       " 'least': 223,\n",
       " 'll': 224,\n",
       " 'both': 225,\n",
       " 'might': 226,\n",
       " 'big': 227,\n",
       " 'bit': 228,\n",
       " 'come': 229,\n",
       " 'new': 230,\n",
       " 'long': 231,\n",
       " 'now': 232,\n",
       " 'original': 233,\n",
       " 'am': 234,\n",
       " 'feel': 235,\n",
       " 'action': 236,\n",
       " 'far': 237,\n",
       " 'music': 238,\n",
       " 'interesting': 239,\n",
       " 'guy': 240,\n",
       " 'She': 241,\n",
       " 'So': 242,\n",
       " 'probably': 243,\n",
       " 'kind': 244,\n",
       " 'done': 245,\n",
       " 'That': 246,\n",
       " 'anything': 247,\n",
       " 'again': 248,\n",
       " 'point': 249,\n",
       " 'role': 250,\n",
       " 'found': 251,\n",
       " 'world': 252,\n",
       " 'series': 253,\n",
       " 'right': 254,\n",
       " 'rather': 255,\n",
       " 'last': 256,\n",
       " 'comedy': 257,\n",
       " 'times': 258,\n",
       " 'script': 259,\n",
       " 'minutes': 260,\n",
       " 'since': 261,\n",
       " 'When': 262,\n",
       " 'each': 263,\n",
       " 'trying': 264,\n",
       " 'family': 265,\n",
       " 'making': 266,\n",
       " 'comes': 267,\n",
       " 'performance': 268,\n",
       " 'worst': 269,\n",
       " 'believe': 270,\n",
       " 'TV': 271,\n",
       " 'd': 272,\n",
       " 'put': 273,\n",
       " 'our': 274,\n",
       " 'woman': 275,\n",
       " 'played': 276,\n",
       " 'main': 277,\n",
       " 'goes': 278,\n",
       " 'time.': 279,\n",
       " 'anyone': 280,\n",
       " ')': 281,\n",
       " 'One': 282,\n",
       " 'course': 283,\n",
       " 'away': 284,\n",
       " 'wasn': 285,\n",
       " 'girl': 286,\n",
       " 'fun': 287,\n",
       " 'looks': 288,\n",
       " 'worth': 289,\n",
       " 'looking': 290,\n",
       " 'hard': 291,\n",
       " 'watched': 292,\n",
       " 'shows': 293,\n",
       " 'different': 294,\n",
       " 'plays': 295,\n",
       " 'having': 296,\n",
       " 'yet': 297,\n",
       " 'seem': 298,\n",
       " 'For': 299,\n",
       " 'takes': 300,\n",
       " 'sure': 301,\n",
       " 'someone': 302,\n",
       " 'especially': 303,\n",
       " 'American': 304,\n",
       " 'My': 305,\n",
       " 'We': 306,\n",
       " 'set': 307,\n",
       " 'said': 308,\n",
       " 'All': 309,\n",
       " 'DVD': 310,\n",
       " 'reason': 311,\n",
       " 'Not': 312,\n",
       " 'play': 313,\n",
       " 'during': 314,\n",
       " 'three': 315,\n",
       " 'left': 316,\n",
       " 'John': 317,\n",
       " 'effects': 318,\n",
       " 'However': 319,\n",
       " 'actor': 320,\n",
       " 'sense': 321,\n",
       " 'ending': 322,\n",
       " 'place': 323,\n",
       " 'true': 324,\n",
       " 'special': 325,\n",
       " 'job': 326,\n",
       " 'book': 327,\n",
       " 'seeing': 328,\n",
       " 'used': 329,\n",
       " 'simply': 330,\n",
       " 'completely': 331,\n",
       " 'everything': 332,\n",
       " 'idea': 333,\n",
       " 'beautiful': 334,\n",
       " 'version': 335,\n",
       " 'money': 336,\n",
       " 'everyone': 337,\n",
       " 'fan': 338,\n",
       " 'let': 339,\n",
       " 'audience': 340,\n",
       " 'shot': 341,\n",
       " 'read': 342,\n",
       " 'wife': 343,\n",
       " 'use': 344,\n",
       " 'nice': 345,\n",
       " '--': 346,\n",
       " 'himself': 347,\n",
       " 'need': 348,\n",
       " 'once': 349,\n",
       " 'excellent': 350,\n",
       " 'screen': 351,\n",
       " '2': 352,\n",
       " 'help': 353,\n",
       " 'together': 354,\n",
       " 'day': 355,\n",
       " 'later': 356,\n",
       " 'recommend': 357,\n",
       " 'until': 358,\n",
       " 'truly': 359,\n",
       " 'couple': 360,\n",
       " 'short': 361,\n",
       " 'poor': 362,\n",
       " 'rest': 363,\n",
       " 'try': 364,\n",
       " 'given': 365,\n",
       " 'high': 366,\n",
       " 'less': 367,\n",
       " 'came': 368,\n",
       " '10': 369,\n",
       " 'Hollywood': 370,\n",
       " 'won': 371,\n",
       " 'getting': 372,\n",
       " 'half': 373,\n",
       " 'tell': 374,\n",
       " 'enjoy': 375,\n",
       " 'else': 376,\n",
       " 'understand': 377,\n",
       " 'After': 378,\n",
       " 'keep': 379,\n",
       " 'At': 380,\n",
       " 'second': 381,\n",
       " 'along': 382,\n",
       " 'To': 383,\n",
       " 'gives': 384,\n",
       " 'year': 385,\n",
       " 'father': 386,\n",
       " 'start': 387,\n",
       " 'Even': 388,\n",
       " 'kids': 389,\n",
       " 'them.': 390,\n",
       " 'mean': 391,\n",
       " 'playing': 392,\n",
       " 'couldn': 393,\n",
       " 'Well': 394,\n",
       " '(and': 395,\n",
       " 'went': 396,\n",
       " 'THE': 397,\n",
       " 'friends': 398,\n",
       " 'small': 399,\n",
       " 'No': 400,\n",
       " 'full': 401,\n",
       " 'production': 402,\n",
       " 'men': 403,\n",
       " 'women': 404,\n",
       " 'performances': 405,\n",
       " 'become': 406,\n",
       " 'doing': 407,\n",
       " 'remember': 408,\n",
       " 'however': 409,\n",
       " 'early': 410,\n",
       " 'camera': 411,\n",
       " 'liked': 412,\n",
       " 'entire': 413,\n",
       " 'mind': 414,\n",
       " 'home': 415,\n",
       " 'supposed': 416,\n",
       " 'classic': 417,\n",
       " 'often': 418,\n",
       " 'felt': 419,\n",
       " 'maybe': 420,\n",
       " 'human': 421,\n",
       " 'next': 422,\n",
       " 'person': 423,\n",
       " 'absolutely': 424,\n",
       " 'line': 425,\n",
       " 'piece': 426,\n",
       " 'stupid': 427,\n",
       " 'wonderful': 428,\n",
       " 'sort': 429,\n",
       " 'black': 430,\n",
       " 'definitely': 431,\n",
       " 'moments': 432,\n",
       " 'certainly': 433,\n",
       " 'His': 434,\n",
       " 'sex': 435,\n",
       " 'budget': 436,\n",
       " 'instead': 437,\n",
       " 'one.': 438,\n",
       " 'seemed': 439,\n",
       " 'against': 440,\n",
       " 'boring': 441,\n",
       " 'While': 442,\n",
       " 'Don': 443,\n",
       " 'Then': 444,\n",
       " 'several': 445,\n",
       " 'him.': 446,\n",
       " 'name': 447,\n",
       " 'waste': 448,\n",
       " 'becomes': 449,\n",
       " 'school': 450,\n",
       " 'loved': 451,\n",
       " 'this.': 452,\n",
       " 'death': 453,\n",
       " 'totally': 454,\n",
       " 'wanted': 455,\n",
       " 'video': 456,\n",
       " 'Also': 457,\n",
       " 'lines': 458,\n",
       " 'perfect': 459,\n",
       " 'dialogue': 460,\n",
       " 'although': 461,\n",
       " 'night': 462,\n",
       " 'able': 463,\n",
       " 'episode': 464,\n",
       " 'top': 465,\n",
       " 'well.': 466,\n",
       " 'Of': 467,\n",
       " 'friend': 468,\n",
       " 'itself': 469,\n",
       " 'hope': 470,\n",
       " 'called': 471,\n",
       " 'written': 472,\n",
       " 'me.': 473,\n",
       " 'Some': 474,\n",
       " 'Now': 475,\n",
       " '\\x96': 476,\n",
       " 'live': 477,\n",
       " 'mother': 478,\n",
       " 'face': 479,\n",
       " 'terrible': 480,\n",
       " 'case': 481,\n",
       " 'already': 482,\n",
       " 'lead': 483,\n",
       " 'story.': 484,\n",
       " 'wrong': 485,\n",
       " 'either': 486,\n",
       " 'wants': 487,\n",
       " 'turn': 488,\n",
       " 'based': 489,\n",
       " 'guys': 490,\n",
       " 'sound': 491,\n",
       " 'tries': 492,\n",
       " 'style': 493,\n",
       " 'low': 494,\n",
       " 'title': 495,\n",
       " 'all.': 496,\n",
       " 'gave': 497,\n",
       " 'children': 498,\n",
       " 'beginning': 499,\n",
       " 'war': 500,\n",
       " 'problem': 501,\n",
       " 'laugh': 502,\n",
       " 'final': 503,\n",
       " 'care': 504,\n",
       " 'house': 505,\n",
       " 'head': 506,\n",
       " 'others': 507,\n",
       " 'enjoyed': 508,\n",
       " 'How': 509,\n",
       " 'finally': 510,\n",
       " 'stars': 511,\n",
       " 'awful': 512,\n",
       " 'turns': 513,\n",
       " 'guess': 514,\n",
       " 'under': 515,\n",
       " 'good.': 516,\n",
       " 'Michael': 517,\n",
       " 'entertaining': 518,\n",
       " 'boy': 519,\n",
       " 'With': 520,\n",
       " 'lost': 521,\n",
       " 'Why': 522,\n",
       " 'life.': 523,\n",
       " 'starts': 524,\n",
       " '(the': 525,\n",
       " 'New': 526,\n",
       " 'took': 527,\n",
       " 'example': 528,\n",
       " 'fine': 529,\n",
       " 'star': 530,\n",
       " 'favorite': 531,\n",
       " 'humor': 532,\n",
       " 'fans': 533,\n",
       " 'writing': 534,\n",
       " 'quality': 535,\n",
       " 'worse': 536,\n",
       " '3': 537,\n",
       " 'Just': 538,\n",
       " 'direction': 539,\n",
       " 'behind': 540,\n",
       " '(': 541,\n",
       " 'works': 542,\n",
       " 'lives': 543,\n",
       " 'says': 544,\n",
       " 'group': 545,\n",
       " 'Mr.': 546,\n",
       " 'viewer': 547,\n",
       " 'kill': 548,\n",
       " 'decent': 549,\n",
       " 'game': 550,\n",
       " 'picture': 551,\n",
       " 'expect': 552,\n",
       " 'drama': 553,\n",
       " 'heard': 554,\n",
       " 'perhaps': 555,\n",
       " 'cannot': 556,\n",
       " 'movies.': 557,\n",
       " 'throughout': 558,\n",
       " 'son': 559,\n",
       " 'extremely': 560,\n",
       " 'lack': 561,\n",
       " 'looked': 562,\n",
       " 'dead': 563,\n",
       " 'car': 564,\n",
       " 'side': 565,\n",
       " 'myself': 566,\n",
       " 'past': 567,\n",
       " 'parts': 568,\n",
       " 'run': 569,\n",
       " 'wouldn': 570,\n",
       " 'late': 571,\n",
       " 'that.': 572,\n",
       " 'On': 573,\n",
       " 'feeling': 574,\n",
       " 'directed': 575,\n",
       " 'dark': 576,\n",
       " 'amazing': 577,\n",
       " 'attempt': 578,\n",
       " 'killed': 579,\n",
       " 'thinking': 580,\n",
       " 'matter': 581,\n",
       " 'killer': 582,\n",
       " 'cinema': 583,\n",
       " 'told': 584,\n",
       " 'act': 585,\n",
       " 'horrible': 586,\n",
       " 'type': 587,\n",
       " 'evil': 588,\n",
       " 'taken': 589,\n",
       " 'fight': 590,\n",
       " 'leave': 591,\n",
       " 'brilliant': 592,\n",
       " 'out.': 593,\n",
       " 'obviously': 594,\n",
       " 'complete': 595,\n",
       " 'town': 596,\n",
       " 'shown': 597,\n",
       " 'David': 598,\n",
       " 'happens': 599,\n",
       " 'Although': 600,\n",
       " 'wonder': 601,\n",
       " 'here.': 602,\n",
       " 'girls': 603,\n",
       " 'particularly': 604,\n",
       " 'strong': 605,\n",
       " 'Oh': 606,\n",
       " 'kid': 607,\n",
       " 'opening': 608,\n",
       " 'bad.': 609,\n",
       " 'across': 610,\n",
       " 'white': 611,\n",
       " 'highly': 612,\n",
       " 'coming': 613,\n",
       " 'exactly': 614,\n",
       " 'James': 615,\n",
       " 'known': 616,\n",
       " 'actress': 617,\n",
       " 'serious': 618,\n",
       " 'hour': 619,\n",
       " 'themselves': 620,\n",
       " 'obvious': 621,\n",
       " 'daughter': 622,\n",
       " 'save': 623,\n",
       " 'Robert': 624,\n",
       " 'involved': 625,\n",
       " 'whose': 626,\n",
       " 'close': 627,\n",
       " 'end.': 628,\n",
       " 'history': 629,\n",
       " 'eyes': 630,\n",
       " 'again.': 631,\n",
       " 'stuff': 632,\n",
       " 'child': 633,\n",
       " 'hand': 634,\n",
       " 'sometimes': 635,\n",
       " 'moment': 636,\n",
       " 'stop': 637,\n",
       " 'soon': 638,\n",
       " 'turned': 639,\n",
       " 'finds': 640,\n",
       " 'stories': 641,\n",
       " 'is.': 642,\n",
       " 'seen.': 643,\n",
       " 'First': 644,\n",
       " 'way.': 645,\n",
       " 'number': 646,\n",
       " 'huge': 647,\n",
       " 'somewhat': 648,\n",
       " 'chance': 649,\n",
       " 'score': 650,\n",
       " 'saying': 651,\n",
       " 'days': 652,\n",
       " 'knew': 653,\n",
       " 'flick': 654,\n",
       " 'wish': 655,\n",
       " 'started': 656,\n",
       " 'voice': 657,\n",
       " 'slow': 658,\n",
       " 'female': 659,\n",
       " 'taking': 660,\n",
       " 'hit': 661,\n",
       " 'despite': 662,\n",
       " 'running': 663,\n",
       " 'art': 664,\n",
       " 'relationship': 665,\n",
       " 'local': 666,\n",
       " 'simple': 667,\n",
       " 'except': 668,\n",
       " 'usually': 669,\n",
       " 'films.': 670,\n",
       " 'order': 671,\n",
       " 'heart': 672,\n",
       " 'English': 673,\n",
       " 'husband': 674,\n",
       " 'tells': 675,\n",
       " 'living': 676,\n",
       " 'aren': 677,\n",
       " 'today': 678,\n",
       " 'important': 679,\n",
       " 'released': 680,\n",
       " 'including': 681,\n",
       " 'shots': 682,\n",
       " 'call': 683,\n",
       " 'police': 684,\n",
       " 'single': 685,\n",
       " 'jokes': 686,\n",
       " 'genre': 687,\n",
       " 'violence': 688,\n",
       " 'her.': 689,\n",
       " '(I': 690,\n",
       " 'usual': 691,\n",
       " 'major': 692,\n",
       " 'due': 693,\n",
       " 'talking': 694,\n",
       " 'British': 695,\n",
       " 'From': 696,\n",
       " 'ends': 697,\n",
       " 'cinematography': 698,\n",
       " 'knows': 699,\n",
       " 'cool': 700,\n",
       " 'happened': 701,\n",
       " 'on.': 702,\n",
       " 'cut': 703,\n",
       " '1': 704,\n",
       " 'change': 705,\n",
       " 'interest': 706,\n",
       " 'song': 707,\n",
       " 'Jack': 708,\n",
       " 'mostly': 709,\n",
       " 'sad': 710,\n",
       " 'hero': 711,\n",
       " 'brother': 712,\n",
       " 'Unfortunately': 713,\n",
       " 'experience': 714,\n",
       " 'appears': 715,\n",
       " 'Man': 716,\n",
       " 'happen': 717,\n",
       " 'giving': 718,\n",
       " 'musical': 719,\n",
       " 'Maybe': 720,\n",
       " 'hours': 721,\n",
       " 'cheap': 722,\n",
       " 'haven': 723,\n",
       " 'bring': 724,\n",
       " 'beyond': 725,\n",
       " 'reality': 726,\n",
       " 'clearly': 727,\n",
       " 'mention': 728,\n",
       " 'murder': 729,\n",
       " 'yourself': 730,\n",
       " 'modern': 731,\n",
       " 'too.': 732,\n",
       " 'upon': 733,\n",
       " 'falls': 734,\n",
       " 'documentary': 735,\n",
       " 'talent': 736,\n",
       " 'sets': 737,\n",
       " 'silly': 738,\n",
       " 'similar': 739,\n",
       " 'funny.': 740,\n",
       " 'certain': 741,\n",
       " 'novel': 742,\n",
       " 'annoying': 743,\n",
       " 'sequence': 744,\n",
       " 'view': 745,\n",
       " 'characters.': 746,\n",
       " 'tried': 747,\n",
       " 'needs': 748,\n",
       " 'strange': 749,\n",
       " 'events': 750,\n",
       " 'gore': 751,\n",
       " 'roles': 752,\n",
       " 'supporting': 753,\n",
       " 'showing': 754,\n",
       " 'body': 755,\n",
       " 'romantic': 756,\n",
       " '?': 757,\n",
       " 'George': 758,\n",
       " 'hilarious': 759,\n",
       " 'kept': 760,\n",
       " 'easily': 761,\n",
       " 'Yes': 762,\n",
       " 'named': 763,\n",
       " 'feels': 764,\n",
       " 'OK': 765,\n",
       " 'comic': 766,\n",
       " 'word': 767,\n",
       " 'problems': 768,\n",
       " 'words': 769,\n",
       " 'bunch': 770,\n",
       " '5': 771,\n",
       " 'episodes': 772,\n",
       " 'actual': 773,\n",
       " 'An': 774,\n",
       " 'career': 775,\n",
       " 'attention': 776,\n",
       " 'typical': 777,\n",
       " 'near': 778,\n",
       " 'brought': 779,\n",
       " 'alone': 780,\n",
       " 'blood': 781,\n",
       " '...': 782,\n",
       " 'fall': 783,\n",
       " 'opinion': 784,\n",
       " 'happy': 785,\n",
       " 'hate': 786,\n",
       " 'songs': 787,\n",
       " 'within': 788,\n",
       " 'nearly': 789,\n",
       " 'above': 790,\n",
       " 'ridiculous': 791,\n",
       " 'using': 792,\n",
       " 'light': 793,\n",
       " 'surprised': 794,\n",
       " 'doubt': 795,\n",
       " 'Like': 796,\n",
       " 'dialog': 797,\n",
       " 'working': 798,\n",
       " 'country': 799,\n",
       " 'whether': 800,\n",
       " 'among': 801,\n",
       " 'clear': 802,\n",
       " 'ones': 803,\n",
       " 'ago': 804,\n",
       " 'age': 805,\n",
       " 'greatest': 806,\n",
       " 'room': 807,\n",
       " 'Peter': 808,\n",
       " 'Its': 809,\n",
       " 'four': 810,\n",
       " 'Is': 811,\n",
       " 'talk': 812,\n",
       " 'Most': 813,\n",
       " 'writer': 814,\n",
       " '4': 815,\n",
       " 'basically': 816,\n",
       " 'means': 817,\n",
       " 'French': 818,\n",
       " 'middle': 819,\n",
       " 'level': 820,\n",
       " 'moving': 821,\n",
       " 'better.': 822,\n",
       " 'possible': 823,\n",
       " 'decided': 824,\n",
       " 'none': 825,\n",
       " 'there.': 826,\n",
       " 'review': 827,\n",
       " 'power': 828,\n",
       " 'theme': 829,\n",
       " 'overall': 830,\n",
       " 'buy': 831,\n",
       " 'comments': 832,\n",
       " 'hear': 833,\n",
       " 'These': 834,\n",
       " 'television': 835,\n",
       " '(which': 836,\n",
       " 'team': 837,\n",
       " 'Richard': 838,\n",
       " 'easy': 839,\n",
       " 'famous': 840,\n",
       " 'message': 841,\n",
       " ').': 842,\n",
       " 'elements': 843,\n",
       " 'deal': 844,\n",
       " 'crap': 845,\n",
       " 'sit': 846,\n",
       " 'add': 847,\n",
       " 'subject': 848,\n",
       " 'Who': 849,\n",
       " 'Her': 850,\n",
       " 'watch.': 851,\n",
       " 'work.': 852,\n",
       " 'soundtrack': 853,\n",
       " 'filmed': 854,\n",
       " 'God': 855,\n",
       " 'learn': 856,\n",
       " 'scary': 857,\n",
       " 'lots': 858,\n",
       " 'you.': 859,\n",
       " 'show.': 860,\n",
       " 'enjoyable': 861,\n",
       " '(as': 862,\n",
       " 'hell': 863,\n",
       " 'stay': 864,\n",
       " 'ten': 865,\n",
       " 'leads': 866,\n",
       " 'Tom': 867,\n",
       " 'parents': 868,\n",
       " 'became': 869,\n",
       " 'five': 870,\n",
       " 'Overall': 871,\n",
       " 'begins': 872,\n",
       " 'etc.': 873,\n",
       " 'predictable': 874,\n",
       " 'emotional': 875,\n",
       " 'up.': 876,\n",
       " 'difficult': 877,\n",
       " 'straight': 878,\n",
       " 'move': 879,\n",
       " 'Paul': 880,\n",
       " 'particular': 881,\n",
       " 'leaves': 882,\n",
       " 'By': 883,\n",
       " 'figure': 884,\n",
       " 'apparently': 885,\n",
       " 'killing': 886,\n",
       " 'reviews': 887,\n",
       " 'effort': 888,\n",
       " 'Here': 889,\n",
       " 'dull': 890,\n",
       " '(or': 891,\n",
       " 'feature': 892,\n",
       " 'keeps': 893,\n",
       " 'storyline': 894,\n",
       " 'sexual': 895,\n",
       " 'previous': 896,\n",
       " 'meets': 897,\n",
       " 'form': 898,\n",
       " 'premise': 899,\n",
       " 'forced': 900,\n",
       " 'editing': 901,\n",
       " 'release': 902,\n",
       " 'write': 903,\n",
       " 'NOT': 904,\n",
       " 'herself': 905,\n",
       " 'sequel': 906,\n",
       " 'poorly': 907,\n",
       " 'realize': 908,\n",
       " 'points': 909,\n",
       " 'needed': 910,\n",
       " 'viewers': 911,\n",
       " 'stand': 912,\n",
       " 'ways': 913,\n",
       " 'personal': 914,\n",
       " 'suspense': 915,\n",
       " 'sister': 916,\n",
       " 'somehow': 917,\n",
       " 'weak': 918,\n",
       " 'Dr.': 919,\n",
       " 'realistic': 920,\n",
       " 'future': 921,\n",
       " 'King': 922,\n",
       " 'York': 923,\n",
       " 'tale': 924,\n",
       " 'rent': 925,\n",
       " 'possibly': 926,\n",
       " 'seriously': 927,\n",
       " 'sequences': 928,\n",
       " 'whom': 929,\n",
       " 'various': 930,\n",
       " 'thriller': 931,\n",
       " '20': 932,\n",
       " 'brings': 933,\n",
       " 'expected': 934,\n",
       " 'incredibly': 935,\n",
       " 'interested': 936,\n",
       " 'reading': 937,\n",
       " 'towards': 938,\n",
       " 'Lee': 939,\n",
       " 'class': 940,\n",
       " 'animation': 941,\n",
       " 'gone': 942,\n",
       " 'average': 943,\n",
       " 'footage': 944,\n",
       " 'features': 945,\n",
       " 'monster': 946,\n",
       " 'viewing': 947,\n",
       " 'Japanese': 948,\n",
       " 'fantastic': 949,\n",
       " 'city': 950,\n",
       " 'admit': 951,\n",
       " 'begin': 952,\n",
       " 'Another': 953,\n",
       " 'male': 954,\n",
       " 'older': 955,\n",
       " 'atmosphere': 956,\n",
       " 'fairly': 957,\n",
       " 'appear': 958,\n",
       " 'follow': 959,\n",
       " 'meet': 960,\n",
       " 'Oscar': 961,\n",
       " 'entertainment': 962,\n",
       " 'crew': 963,\n",
       " 'open': 964,\n",
       " 'material': 965,\n",
       " 'result': 966,\n",
       " 'eventually': 967,\n",
       " 'minute': 968,\n",
       " 'nor': 969,\n",
       " 'manages': 970,\n",
       " 'Disney': 971,\n",
       " 'spent': 972,\n",
       " 'imagine': 973,\n",
       " 'Joe': 974,\n",
       " 'worked': 975,\n",
       " 'leading': 976,\n",
       " 'Or': 977,\n",
       " '80': 978,\n",
       " 'total': 979,\n",
       " 'theater': 980,\n",
       " 'cheesy': 981,\n",
       " 'crime': 982,\n",
       " 'forget': 983,\n",
       " 'disappointed': 984,\n",
       " 'unique': 985,\n",
       " 'meant': 986,\n",
       " 'War': 987,\n",
       " 'attempts': 988,\n",
       " 'surprise': 989,\n",
       " 'wait': 990,\n",
       " 'dramatic': 991,\n",
       " 'America': 992,\n",
       " 'political': 993,\n",
       " 'period': 994,\n",
       " 'comment': 995,\n",
       " 'memorable': 996,\n",
       " 'deep': 997,\n",
       " 'create': 998,\n",
       " 'writers': 999,\n",
       " 'front': 1000,\n",
       " 'Great': 1001,\n",
       " 'plot.': 1002,\n",
       " ...}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    "numWords = 1000\n",
    "\n",
    "\n",
    "\n",
    "def CreateDict(data, topN):\n",
    "    \n",
    "    wordfreqs = {}\n",
    "    \n",
    "    for review in data:\n",
    "\n",
    "        for word in review:\n",
    "            if word not in wordfreqs:\n",
    "                wordfreqs[word] = 0\n",
    "            wordfreqs[word] += 1\n",
    "    \n",
    "  \n",
    "    ##Hint: \"\" (or the empty string) is actually \n",
    "    ### the most common word but we want to cast it as an unknown word, what index should we index it as then?\n",
    "    final_dict = {}\n",
    "    \n",
    "    \n",
    "    for idx, word in enumerate(sorted(wordfreqs, key=wordfreqs.get, reverse=True)[1:]):\n",
    "        \n",
    "        if idx == numWords + 3:\n",
    "            break\n",
    "        \n",
    "        final_dict[word] = idx + 3\n",
    "        print(word, final_dict[word])\n",
    "        \n",
    "    return final_dict\n",
    "    \n",
    "wordCounter = CreateDict(imdb_x, numWords)\n",
    "wordCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete  replaceByIndex which will replace known words with their index and unknown words with a 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounter['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def replaceByIndex(data, wordCounter):\n",
    "    \n",
    "#     for i, review in enumerate(data):\n",
    "#         for j, word in enumerate(review):\n",
    "#             try:\n",
    "#                 data[i][j] = wordCounter[word]\n",
    "#             except KeyError:\n",
    "#                 data[i][j] = 2\n",
    "#     return data\n",
    "\n",
    "    [[print(word, review) for word in review] for review in data]\n",
    "    return [[wordCounter[word] if word in wordCounter else 2 for word in review] for review in data]\n",
    "#     return [[print(wordCounter[word]) if word in wordCounter else 2] for review in data]\n",
    "            \n",
    "    \n",
    "\n",
    "imdb_x_copy = replaceByIndex(imdb_x, wordCounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imdb_x_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-77e3083e5169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimdb_x_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "imdb_x_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to process the data into NumPy arrays of sequences that are all length 200. We will use these criteria: \n",
    "* We want to add a 1 at the beginning of every review to signal the beginning of the text.\n",
    "* If a given sequence is shorter than 200 tokens we want to pad the beginning of the sequence out with zeros so that the sequence is 200 long. \n",
    "* Else if the sequence is longer than 200 (including the starting 1) we want to cut it down to length 200. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \n",
    "    #YOUR CODE HERE \n",
    "    \n",
    "    return processed\n",
    "\n",
    "imdb_x = process_data(imdb_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Separate the dataset into train and test sets, test set should be 1/3 of the set.</b> <p>\n",
    "This sklearn method will make your life much easier: \n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "x_train_proc, x_test_proc, y_train, y_test = #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point **your job is done!!!** Congratulations, if done correctly, the sentences are processed and ready to be used as features and labels to train a Recurrent Neural Network (LSTM). You will learn how to do this yourself in the next couple weeks. For now, you can just sit back and \"follow along\" as we build this model using Keras and then train it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we will do is initialize the model using Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Sequential\n",
    "\n",
    "imdb_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add an embedding layer. The purpose of an embedding layer is to take a sequence of integers representing words in our case and turn each integer into a dense vector in some embedding space. (This is essentially the idea of Word2Vec https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf). We want to create an embedding layer with vocab size equal to the max num words we allowed when we loaded the data (in this case 1000), and a fixed dense vector of size 32. Then we have to specify the max length of our sequences and we want to mask out zeros in our sequence since we used zero to pad.\n",
    "Use the docs for embedding layer to fill out the missing entries: https://keras.io/layers/embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "imdb_model.add(Embedding(1000, 32, input_length=200, mask_zero=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(a)** We add an LSTM layer with 32 outputs, then a Dense layer with 16 neurons, then a relu activation, then a dense layer with 1 neuron, then a sigmoid activation. Then we print out the model summary. The Keras documentation is here: https://keras.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Activation\n",
    "imdb_model.add(LSTM(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_model.add(Dense(units=16, activation='relu'))\n",
    "imdb_model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(b)** Now we compile the model with binary cross entropy, and the adam optimizer. We include accuracy as a metric in the compile. Then train the model on the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_model.fit(x_train_proc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", imdb_model.evaluate(x_test_proc, y_test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you did the data pre-processing correctly you should be getting around an 80% accuracy. congratulations, that is much better than random! \n",
    "<i>If you are getting a test accuracy that is significantly lower, you probably did something wrong, slack your NMEP team or go to office hours to get help sorting it out :) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can look at our predictions and the sentences they correspond to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = imdb_model.predict(x_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_id = wordCounter\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items() if value < 2000}\n",
    "def get_words(token_sequence):\n",
    "    return ' '.join(id_to_word[token] for token in token_sequence)\n",
    "\n",
    "def get_sentiment(y_pred, index):\n",
    "    return 'Positive' if y_pred[index] else 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = [i for i in y_test]\n",
    "y_pred = np.vectorize(lambda x: int(x >= 0.5))(y_pred)\n",
    "correct = []\n",
    "incorrect = []\n",
    "for i, pred in enumerate(y_pred):\n",
    "    if y_test[i] == pred:\n",
    "        correct.append(i)\n",
    "    else:\n",
    "        incorrect.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we print out one of the sequences we got correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_sentiment(y_pred, correct[10]))\n",
    "print(get_words(x_test_proc[correct[10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And one we got wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_sentiment(y_pred, incorrect[10]))\n",
    "print(get_words(x_test_proc[incorrect[10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see the amount of UNKNOWN characters in the sequence cause by having only 1000 vocab words is hurting our performance. If you want, go back and increase the number of vocab words to 2000 and compare your accuracy \n",
    "(If you do so, remember to change your embedding parameter from 1000 to 2000 as well; you should get ~85% accuracy). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## And that's it! Now you should feel like a data engineering/preprocessing expert :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
