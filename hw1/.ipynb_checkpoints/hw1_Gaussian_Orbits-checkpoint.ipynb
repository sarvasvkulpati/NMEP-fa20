{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Gaussian Orbits\n",
    "\n",
    "Imports needed in this notebook: `numpy` (as np), `matplotlib.pyplot` (as plt), from sklearn: `LinearRegression`, `ElasticNet`, and `mean_squared_error`. Search up documentation if you have issues with any of the scikit learn things. This first part will be a warmup with numpy, linear regression, and scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll generate some random data and find the line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0.5407950116788653, 0.605046051439007),\n",
       " (0.19228697172885936, 0.19238053390777404),\n",
       " (0.1794588068553257, 0.23470282920827895),\n",
       " (0.37226897178527424, 0.3424711532448536),\n",
       " (1.7399701954117999, 1.8647217700098953),\n",
       " (0.12952526892269442, 0.1090896216748245),\n",
       " (0.3117510285683833, 0.708794138820112),\n",
       " (1.010796295592431, 0.9732839046869113),\n",
       " (1.4115059770562812, 1.3087216526635808),\n",
       " (1.1251346802066788, 1.3332244252429428),\n",
       " (0.12927929392404022, 0.22657166489546088),\n",
       " (0.2595896953059222, 0.273991401884433),\n",
       " (2.3617752441388675, 2.451451021162417),\n",
       " (0.12859659322602418, 0.011167342150302906),\n",
       " (0.433613773278137, 0.1800235997858433),\n",
       " (0.32720447828199134, 0.33211270812038474),\n",
       " (1.0384145784329513, 1.262284171926907),\n",
       " (1.2399827790194529, 1.1163762231839602),\n",
       " (0.12697243855329696, 0.16638400414639143),\n",
       " (0.46801309601411484, 0.4286084623683406)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = 20\n",
    "\n",
    "def gen_data(n):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        rand = abs(np.random.randn())\n",
    "        x += [rand]\n",
    "        y += [.15 * np.random.randn() + rand]\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "    \n",
    "    return (x, y)\n",
    "\n",
    "data = gen_data(num_data)\n",
    "data = [(data[0][i], data[1][i]) for i in range(num_data)]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Linear Regression\n",
    "Now, `data` is a list of tuples of data. Perform linear regression to find the line of best fit, using only numpy. Minimize squared loss. Use matplotlib to plot your line of best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy() #data1 is a copy of data, dont modify data since we'll use it later\n",
    "#YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Linear Regression\n",
    "Now, do the same thing, except using Scikit Learn. I recommend reading some documentation, specifically here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = data.copy()\n",
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Orbits\n",
    "\n",
    "In this homework, we will use linear regression methods in order to determine the orbits of heavenly bodies.\n",
    "\n",
    "### Background\n",
    "\n",
    "In 1801 the minor planet Ceres was first observed for a period of 40 days before moving behind the sun. To predict the location of Ceres astronomers would have to solve complicated non-linear differential equations, quite a task in an era before computers or calculators. However, Carl Friedrich Gauss had another idea. By single handedly developing the theory of least squares and linear regression and applying it to the problem of finding Ceres, Gauss managed to accurately predict the location of the minor planet nearly a year after it's last sighting.\n",
    "\n",
    "In this problem we likewise attempt to predict the orbit of a \"planet\" and in the process \"derive\" the formula for an ellipse, the shape of orbits of heavenly bodies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate Data\n",
    "\n",
    "The idea here is we generate data in the shape of an ellipse. To do this we use the formula of an ellipse in polar coordinates:\n",
    "\n",
    "$$ r = \\frac{ep}{1-e \\cos{\\theta}} $$\n",
    "\n",
    "where $ e $ is the eccentricity and $ p $ is the distance from the minor axis to the directrix (read \"length\"). In addition, we add random noise to the data.\n",
    "\n",
    "We will then try to fit curves to our synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(e, p, o):\n",
    "    theta = np.linspace(0,2*np.pi, 200)\n",
    "\n",
    "    # Ellipse with eccentricity e\n",
    "    # Axis \"length\" p\n",
    "    # Offset by .5 angularly\n",
    "    r = e*p/(1-e*np.cos(theta - o)) \n",
    "\n",
    "    # transform to cartesian\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "\n",
    "    # Add noise\n",
    "    x += np.random.randn(x.shape[0]) / 20\n",
    "    y += np.random.randn(y.shape[0]) / 20\n",
    "\n",
    "    # plot\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "    # saving\n",
    "    np.save('x.npy', x)\n",
    "    np.save('y.npy', y)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_data(.5, 2, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use sklearn's LinearRegression\n",
    "\n",
    "Try to fit a `LinearRegression` model to `x` and `y` (let $ x $ be the independent variable and $ y $ be the dependent variable). Print out the `mean_squared_error` you get and plot both `x`, `y` (scatter plot), and the predicted orbit (line plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the best approach for our data.  Please explain why below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Replace with explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Experimentation time!\n",
    "\n",
    "Try adding new features to your linear model by manipulating $ x $! For example, try adding a quadratic term, $ x^2 $ or a root term like $ \\sqrt{x} $. Print out the MSE of your model and plot both `x`, `y` (scatter plot), and the predicted orbit (line plot). This time, your model should take in an expanded set of features and predict $ y $.\n",
    "\n",
    "Hint: `np.vstack` may be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still not the best idea, please explain:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Replace with explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plane Curves\n",
    "\n",
    "As you've probably figured out, the above two methods are pretty crap at predicting orbits. What we really need to do is predict a curve in the plane. First, let's erase some of the data so what we're doing is actually a challenge. Just run the code in the next box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask where x < 0 or y < 0\n",
    "def mask():\n",
    "    global x\n",
    "    global y\n",
    "    \n",
    "    mask = (x < 0) + (y < 0)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    # plot erased data\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the most general form of a plane curve is\n",
    "\n",
    "$$ f(x,y) = 0 $$\n",
    "\n",
    "In order to simplify our lives a bit, let's restrict this to something of the form:\n",
    "\n",
    "$$ ax^2 + bxy + cy^2 + dx + ey + f = 0 $$\n",
    "\n",
    "You may recognize this as the general form of a conic! Let's take our data and try to predict the best possible coefficients here using least squares. This way, these coefficients should give the best possible approximation to the orbit. Print your predicted coefficients.\n",
    "\n",
    "Hint 1: Think about the features you need. (6 total)\n",
    "\n",
    "Hint 2: Use the normal equation instead of sklearn.\n",
    "\n",
    "Hint 3: This is going to fail, why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Reformulation\n",
    "\n",
    "The above should fail for a very trivial (pun intended) reason. The reason is that if we simply set all the coefficients to zero, we get a perfect solution! We can see this in the normal equations:\n",
    "\n",
    "$$ (A^TA)^{-1} A^T b = x $$\n",
    "\n",
    "but $ b = \\vec 0 $ in our case, thus $ x = \\vec 0 $ trivially.\n",
    "\n",
    "How do we get around this? One thing we can do is to not have $ b = \\vec 0 $. To do this, let us modify the general form of a plane curve a bit:\n",
    "\n",
    "$$ f(x,y) + 1 = 1 $$\n",
    "\n",
    "Now our restricted plane curve will be of the form\n",
    "\n",
    "$$ ax^2 + bxy + cy^2 + dx + ey + f + 1 = 1 $$\n",
    "\n",
    "Is this just an aesthetic change? or will this actually help? Code it up and find out! Plot your model using the handy dandy `plot_conic` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should help you plot your ellipses:\n",
    "\n",
    "def plot_conic(coeff):\n",
    "    '''\n",
    "    params\n",
    "    ------\n",
    "    coeff : array[6] floats\n",
    "        Array of 6 floats, corresponding to \n",
    "        a, b, c, d, e, and f respectively\n",
    "        in the equation above\n",
    "    '''\n",
    "    xv = np.linspace(-9, 9, 400)\n",
    "    yv = np.linspace(-5, 5, 400)\n",
    "    xv, yv = np.meshgrid(xv, yv)\n",
    "\n",
    "    def axes():\n",
    "        plt.axhline(0, alpha=.1)\n",
    "        plt.axvline(0, alpha=.1)\n",
    "\n",
    "    axes()\n",
    "    plt.contour(xv, yv, xv*xv*coeff[0] + xv*yv*coeff[1] + yv*yv*coeff[2] + xv*coeff[3] + yv*coeff[4] + coeff[5], [0], colors='k')\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ridge\n",
    "\n",
    "So, reformulating the problem might have worked, but more than likely it didn't work too well. Here's some code to generate new data. Try running the above model multiple times on different data. More than likely most of them will look terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate data\n",
    "gen_data(.5, 2, .5)\n",
    "mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that our method is too unstable. It turns out the Ridge Regression as a regularizer can reduce numerical instability and constrain under-constrained problems. (The math homework with the Ridge Derivation walks you through why this is the case)\n",
    "\n",
    "The closed form solution for Ridge Regression is the following:\n",
    "\n",
    "$$ w^*_{\\text{RIDGE}} = (X^TX + \\lambda I)^{-1}X^Ty$$\n",
    "\n",
    "\n",
    "Rewrite the regression from above using ridge regression (try using $\\lambda = 1$) and see how well it does. Plot out the model using `plot_conic`. Compare the results with the previous method.\n",
    "\n",
    "Hint: Use the `regenerate data` block to try new data\n",
    "\n",
    "Hint: There is really only one extra term between this question and the previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. \"Deriving\" an Ellipse\n",
    "\n",
    "LASSO regularization is a _sparse feature selector_ in the sense that it zeros out \"useless\" features and keeps relevant features. It's a good way to reduce the number of features you have to use. \n",
    "\n",
    "In this case we're going to pretend we don't know what form the equation of an ellipse takes. We can add random monomials to form a guess:\n",
    "\n",
    "$$ ax^2 + bxy + cy^2 + dx + ey + f + gx^3 + hy^3 + jx^2y + \\cdots + 1 = 1 $$\n",
    "\n",
    "The idea here is that if we use LASSO regression on the above equation, the terms irrelevant to an ellipse will \"zero out\" and the quadratic and lower terms won't! Try this out, and print out the coefficients. No gurantees this will works 100% :), but you should find that all coefficients greater than quadratic zero out.\n",
    "\n",
    "`Hint`: We want to keep the ridge regularization to maintain numerical stabilitiy. So we need a combined Ridge and LASSO regression. This model is called `ElasticNet` from sklearn. Use that model.\n",
    "\n",
    "`Hint`: You might have to play around with the parameters a bit. I used these `l1_ratio=.23, alpha=.01` to produce some pretty good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Evaluate this model!\n",
    "\n",
    "Run this code block below. This code block assumes that you have an array called `coeff` which has  10 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xv = np.linspace(-9, 9, 400)\n",
    "yv = np.linspace(-5, 5, 400)\n",
    "xv, yv = np.meshgrid(xv, yv)\n",
    "\n",
    "def axes():\n",
    "    plt.axhline(0, alpha=.1)\n",
    "    plt.axvline(0, alpha=.1)\n",
    "\n",
    "axes()\n",
    "plt.contour(xv, yv, xv*xv*coeff[0] + xv*yv*coeff[1] + yv*yv*coeff[2] + xv*coeff[3] + yv*coeff[4] + coeff[5] - 1 + coeff[6]*xv*xv*xv + coeff[7]*yv*yv*yv + coeff[8]*xv*xv*yv + coeff[9]*xv*yv*yv , [0], colors='k')\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As demonstrated above, ridge regression can help overcome numerical instability and generalization issues that ordinary least squares (OLS) can fall short to. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
